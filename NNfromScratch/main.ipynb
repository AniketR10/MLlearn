{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_gaussian_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array([\n",
    "    [1,2,3],\n",
    "    [6,7,8],\n",
    "    [7,8,9],\n",
    "    [3,4,5],\n",
    "    [4,5,6],\n",
    "])\n",
    "\n",
    "X = samples\n",
    "targets = np.array([False, True, True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array : [False  True  True False False]\n",
      "Unique array : [False  True]\n",
      "Indices : [0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "uniques, indices = np.unique(targets, return_inverse = True)\n",
    "print(f\"Original array : {targets}\")\n",
    "print(f\"Unique array : {uniques}\")\n",
    "print(f\"Indices : {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n_samples = targets.shape[0]\n",
    "n_classes = len(uniques)\n",
    "y = np.zeros((n_samples, n_classes))\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(n_samples))\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False False] \n",
      "\n",
      "one hot encoding targets:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y[np.arange(n_samples), indices] = 1\n",
    "print(targets, '\\n')\n",
    "print(\"one hot encoding targets:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "Dataset size : 5\n",
      "Features size : 3\n"
     ]
    }
   ],
   "source": [
    "# The shape of our dataset\n",
    "print(X.shape)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "print(f\"Dataset size : {n_samples}\")\n",
    "print(f\"Features size : {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of units in the hidden layer\n",
    "n_hidden_units = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "Wh = np.random.uniform(low=-0.5, high=0.5, size=(n_features, n_hidden_units))\n",
    "bh = np.zeros((1, n_hidden_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.27132064 -0.47924805  0.13364823  0.24880388]\n",
      " [-0.00149299 -0.27520335 -0.30193714  0.26053071]\n",
      " [-0.33088916 -0.41166019  0.18535982  0.45339335]]\n"
     ]
    }
   ],
   "source": [
    "print(Wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (5, 3)\n",
      "hidden weights shape : (3, 4)\n",
      "hidden biases shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"input shape: {X.shape}\")\n",
    "print(f\"hidden weights shape : {Wh.shape}\")\n",
    "print(f\"hidden biases shape: {bh.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.27132064 -0.47924805  0.13364823  0.24880388]\n",
      " [-0.00149299 -0.27520335 -0.30193714  0.26053071]\n",
      " [-0.33088916 -0.41166019  0.18535982  0.45339335]] \n",
      "\n",
      "Weights of the first hidden unit: \n",
      "[[ 0.27132064]\n",
      " [-0.00149299]\n",
      " [-0.33088916]]\n"
     ]
    }
   ],
   "source": [
    "# the weights of the first hidden unit\n",
    "# reshape is used just to display the result in column format\n",
    "print(Wh, '\\n')\n",
    "print(\"Weights of the first hidden unit: \")\n",
    "print(Wh[:,0].reshape(3,1)) \n",
    "# this code snippet is for explaination only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "[[-0.72433282 -2.26463532  0.08585342  2.13004535]\n",
      " [-1.02964036 -8.09519327  0.17120801  6.94368505]\n",
      " [-1.09070187 -9.26130486  0.18827893  7.90641299]\n",
      " [-0.84645584 -4.5968585   0.11999526  4.05550123]\n",
      " [-0.90751735 -5.76297009  0.13706617  5.01822917]]\n"
     ]
    }
   ],
   "source": [
    "h1 = np.dot(X, Wh) + bh\n",
    "print(h1.shape)\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  ReLU (h1) :\n",
      "[[-0.72433282 -2.26463532  0.08585342  2.13004535]\n",
      " [-1.02964036 -8.09519327  0.17120801  6.94368505]\n",
      " [-1.09070187 -9.26130486  0.18827893  7.90641299]\n",
      " [-0.84645584 -4.5968585   0.11999526  4.05550123]\n",
      " [-0.90751735 -5.76297009  0.13706617  5.01822917]] \n",
      "\n",
      "After ReLU (a1): \n",
      "[[0.         0.         0.08585342 2.13004535]\n",
      " [0.         0.         0.17120801 6.94368505]\n",
      " [0.         0.         0.18827893 7.90641299]\n",
      " [0.         0.         0.11999526 4.05550123]\n",
      " [0.         0.         0.13706617 5.01822917]]\n"
     ]
    }
   ],
   "source": [
    "# passing values thru relU\n",
    "a1 = np.maximum(0,h1)\n",
    "print(\"before  ReLU (h1) :\")\n",
    "print(h1, '\\n')\n",
    "print(\"After ReLU (a1): \")\n",
    "print(a1) # a1 is the output of the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "Wo = np.random.uniform(low=-0.5, high=0.5, size = (n_hidden_units, n_classes))\n",
    "bo = np.zeros((1,n_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04340494 -0.22163061]\n",
      " [-0.07548241  0.34477613]\n",
      " [-0.49528114 -0.37843088]\n",
      " [ 0.17074908  0.32585276]]\n"
     ]
    }
   ],
   "source": [
    "print(Wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer output shape: (5, 4)\n",
      "Output weights shape: (4, 2)\n",
      "Output biases shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hidden layer output shape: {a1.shape}\")\n",
    "print(f\"Output weights shape: {Wo.shape}\")\n",
    "print(f\"Output biases shape: {bo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "[[0.32118171 0.66159156]\n",
      " [1.10083177 2.19782851]\n",
      " [1.25676178 2.5050759 ]\n",
      " [0.63304174 1.27608634]\n",
      " [0.78897175 1.58333373]]\n"
     ]
    }
   ],
   "source": [
    "h2 = np.dot(a1, Wo) + bo\n",
    "print(h2.shape)\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3787561   1.93787412]\n",
      " [ 3.00666583  9.005437  ]\n",
      " [ 3.51402386 12.24448824]\n",
      " [ 1.88333047  3.5825912 ]\n",
      " [ 2.20113194  4.87116792]]\n"
     ]
    }
   ],
   "source": [
    "# softmax func\n",
    "#first we will calculate the numerators\n",
    "e_x = np.exp(h2)\n",
    "print(e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22026.465794806718\n",
      "2.6881171418161356e+43\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT0001\\AppData\\Local\\Temp\\ipykernel_19632\\969166390.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  print(np.exp(1000))\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(10))\n",
    "print(np.exp(100))\n",
    "print(np.exp(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.5050758959413426)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32118171 0.66159156]\n",
      " [1.10083177 2.19782851]\n",
      " [1.25676178 2.5050759 ]\n",
      " [0.63304174 1.27608634]\n",
      " [0.78897175 1.58333373]] \n",
      "\n",
      "Maximum value from each row: \n",
      "[0.66159156 2.19782851 2.5050759  1.27608634 1.58333373]\n"
     ]
    }
   ],
   "source": [
    "print(h2, '\\n')\n",
    "print(\"Maximum value from each row: \")\n",
    "print(np.max(h2,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,2) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# this will show error\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#as we are subtracting the 2 columns from the 5 columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m np.exp(\u001b[43mh2\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (5,2) (5,) "
     ]
    }
   ],
   "source": [
    "# this will show error\n",
    "#as we are subtracting the 2 columns from the 5 columns\n",
    "np.exp(h2 - np.max(h2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66159156],\n",
       "       [2.19782851],\n",
       "       [2.5050759 ],\n",
       "       [1.27608634],\n",
       "       [1.58333373]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(h2, axis=1, keepdims = True) #hence we make the row and column same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71147867 1.        ]\n",
      " [0.33387229 1.        ]\n",
      " [0.28698822 1.        ]\n",
      " [0.52568947 1.        ]\n",
      " [0.45186944 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# we can now calculate\n",
    "e_x = np.exp(h2 - np.max(h2, axis = 1, keepdims = True))\n",
    "print(e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.71147867],\n",
       "       [1.33387229],\n",
       "       [1.28698822],\n",
       "       [1.52568947],\n",
       "       [1.45186944]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will calculate the softmax denominators\n",
    "np.sum(e_x, axis=1, keepdims = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41570992, 0.58429008],\n",
       "       [0.25030304, 0.74969696],\n",
       "       [0.22299211, 0.77700789],\n",
       "       [0.34455863, 0.65544137],\n",
       "       [0.31123284, 0.68876716]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = e_x / np.sum(e_x, axis=1, keepdims= True) #  according to softmax formula\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0.41570992 0.58429008]\n",
      " [0.25030304 0.74969696]\n",
      " [0.22299211 0.77700789]\n",
      " [0.34455863 0.65544137]\n",
      " [0.31123284 0.68876716]]\n"
     ]
    }
   ],
   "source": [
    "#calculate CCE loss (full version)\n",
    "print(y)\n",
    "print(y_hat)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87776756, 0.2880862 , 0.25230477, 1.06549102, 1.16721398])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#component wise multiply and summation in each row\n",
    "np.sum(y * -np.log(y_hat), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41570992 0.58429008]\n",
      " [0.25030304 0.74969696]\n",
      " [0.22299211 0.77700789]\n",
      " [0.34455863 0.65544137]\n",
      " [0.31123284 0.68876716]]\n"
     ]
    }
   ],
   "source": [
    "y_hat_clipped = np.clip(y_hat, np.finfo(float).eps, 1 - np.finfo(float).eps) # clip function is used so that we can use it to to let log(0) to show error\n",
    "print(y_hat_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87776756, 0.2880862 , 0.25230477, 1.06549102, 1.16721398])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_logs = np.sum(y * -np.log(y_hat_clipped), axis = 1)\n",
    "neg_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this forward pass is : 0.7301727079439226\n"
     ]
    }
   ],
   "source": [
    "cce_loss = np.mean(neg_logs)\n",
    "print(f\"The loss after this forward pass is : {cce_loss}\") #this completes our forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]] \n",
      "\n",
      "y-hat\n",
      "[[0.41570992 0.58429008]\n",
      " [0.25030304 0.74969696]\n",
      " [0.22299211 0.77700789]\n",
      " [0.34455863 0.65544137]\n",
      " [0.31123284 0.68876716]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y\")\n",
    "print(y, '\\n')\n",
    "print(\"y-hat\")\n",
    "print(y_hat_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11685802  0.11685802]\n",
      " [ 0.05006061 -0.05006061]\n",
      " [ 0.04459842 -0.04459842]\n",
      " [-0.13108827  0.13108827]\n",
      " [-0.13775343  0.13775343]]\n"
     ]
    }
   ],
   "source": [
    "# we will normalize also so that the gradient is not affected by the size of the gradient.\n",
    "dloss_dh2 = (y_hat - y) / n_samples\n",
    "print(dloss_dh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.08585342 2.13004535]\n",
      " [0.         0.         0.17120801 6.94368505]\n",
      " [0.         0.         0.18827893 7.90641299]\n",
      " [0.         0.         0.11999526 4.05550123]\n",
      " [0.         0.         0.13706617 5.01822917]]\n"
     ]
    }
   ],
   "source": [
    "dh2_dWo = a1\n",
    "print(dh2_dWo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wo: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "# now we will multiply \n",
    "print(f\"Wo: {Wo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh2_dwo: (5, 4)\n",
      "dloss_dh2: (5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"dh2_dwo: {dh2_dWo.shape}\")\n",
    "print(f\"dloss_dh2: {dloss_dh2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5) * (5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'{dh2_dWo.T.shape} * {dloss_dh2.shape}') # we take the transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.08585342 2.13004535]\n",
      " [0.         0.         0.17120801 6.94368505]\n",
      " [0.         0.         0.18827893 7.90641299]\n",
      " [0.         0.         0.11999526 4.05550123]\n",
      " [0.         0.         0.13706617 5.01822917]]\n"
     ]
    }
   ],
   "source": [
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11685802  0.11685802]\n",
      " [ 0.05006061 -0.05006061]\n",
      " [ 0.04459842 -0.04459842]\n",
      " [-0.13108827  0.13108827]\n",
      " [-0.13775343  0.13775343]]\n"
     ]
    }
   ],
   "source": [
    "print(dloss_dh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.08585342 0.17120801 0.18827893 0.11999526 0.13706617]\n",
      " [2.13004535 6.94368505 7.90641299 4.05550123 5.01822917]]\n"
     ]
    }
   ],
   "source": [
    "dh2_dWo = a1.T\n",
    "print(dh2_dWo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient for the outptut weights (Wo) :\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.02767625  0.02767625]\n",
      " [-0.77160119  0.77160119]]\n"
     ]
    }
   ],
   "source": [
    "#now we can calculate the derivative of Lcce wrt W0\n",
    "#gradient of the output weight\n",
    "dloss_dWo = np.dot(dh2_dWo, dloss_dh2)\n",
    "print(\"The gradient for the outptut weights (Wo) :\")\n",
    "print(dloss_dWo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient for the output biases (bo):\n",
      "[[-0.29104069  0.29104069]]\n"
     ]
    }
   ],
   "source": [
    "# gradient of the output baises\n",
    "dloss_dbo = np.sum(dloss_dh2, axis =0, keepdims= True)\n",
    "print(\"The gradient for the output biases (bo):\")\n",
    "print(dloss_dbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    " #now we will calculate the gradient of the hidden weights and biases\n",
    "dh2_da1 = Wo.T\n",
    "print(dh2_da1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(dloss_dh2.shape)\n",
    "print(Wo.T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04340494 -0.22163061]\n",
      " [-0.07548241  0.34477613]\n",
      " [-0.49528114 -0.37843088]\n",
      " [ 0.17074908  0.32585276]]\n"
     ]
    }
   ],
   "source": [
    "print(Wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights between first hidden unit and each output unit:\n",
      "[ 0.04340494 -0.22163061]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights between first hidden unit and each output unit:\")\n",
    "print(Wo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11685802  0.11685802]\n",
      " [ 0.05006061 -0.05006061]\n",
      " [ 0.04459842 -0.04459842]\n",
      " [-0.13108827  0.13108827]\n",
      " [-0.13775343  0.13775343]]\n"
     ]
    }
   ],
   "source": [
    "print(dloss_dh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "[[-0.03097153  0.04911058  0.01365489  0.01812511]\n",
      " [ 0.01326784 -0.0210384  -0.0058496  -0.00776458]\n",
      " [ 0.01182017 -0.01874287 -0.00521134 -0.00691738]\n",
      " [-0.03474305  0.05509097  0.0153177   0.02033227]\n",
      " [-0.03650956  0.05789206  0.01609653  0.02136606]]\n"
     ]
    }
   ],
   "source": [
    "dloss_da1 = np.dot(dloss_dh2, dh2_da1)\n",
    "print(dloss_da1.shape)\n",
    "print(dloss_da1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.72433282 -2.26463532  0.08585342  2.13004535]\n",
      " [-1.02964036 -8.09519327  0.17120801  6.94368505]\n",
      " [-1.09070187 -9.26130486  0.18827893  7.90641299]\n",
      " [-0.84645584 -4.5968585   0.11999526  4.05550123]\n",
      " [-0.90751735 -5.76297009  0.13706617  5.01822917]] \n",
      "\n",
      "[[0. 0. 1. 1.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "da1_dh1 = np.zeros(h1.shape, dtype = np.float32)\n",
    "da1_dh1[h1 > 0] = 1\n",
    "print(h1, '\\n')\n",
    "print(da1_dh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dloss_da1: (5, 4)\n",
      "da1_dh1: (5, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"dloss_da1: {dloss_da1.shape}\")\n",
    "print(f\"da1_dh1: {da1_dh1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.          0.          0.01365489  0.01812511]\n",
      " [ 0.         -0.         -0.0058496  -0.00776458]\n",
      " [ 0.         -0.         -0.00521134 -0.00691738]\n",
      " [-0.          0.          0.0153177   0.02033227]\n",
      " [-0.          0.          0.01609653  0.02136606]]\n"
     ]
    }
   ],
   "source": [
    "dloss_dh1 = da1_dh1 * dloss_da1\n",
    "print(dloss_dh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "dh1_dWo = X.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "dloss_dWh = np.dot(dh1_dWo, dloss_dh1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden weights: (3, 4)\n",
      "dh1_dWo: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hidden weights: {Wh.shape}\")\n",
    "print(f\"dh1_dWo: {dloss_dWh.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.03400818, 0.04514148]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dloss_dbh = np.sum(dloss_dh1, axis=  0, keepdims = True)\n",
    "dloss_dbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr = 0.01\n",
    "\n",
    "#upadtes output weights and biases\n",
    "new_Wo = Wo - lr*dloss_dWo\n",
    "new_bo = bo - lr * dloss_dbo\n",
    "\n",
    "#updates hidden weights and biases.\n",
    "new_Wh = Wh - lr * dloss_dWh\n",
    "new_bh = bh - lr * dloss_dbh\n",
    "\n",
    "#This completes our backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New loss: 0.7168031908508434\n",
      "Previous loss: 0.7301727079439226\n"
     ]
    }
   ],
   "source": [
    "# To check if the loss minimized or not we again do a forward pass with thenew Values\n",
    "h1 = np.dot(X, new_Wh) + new_bh\n",
    "a1 = np.maximum(0, h1)\n",
    "h2 = np.dot(a1, new_Wo) + new_bo\n",
    "\n",
    "# Softmax\n",
    "e_x = np.exp(h2 - np.max(h2, axis=1, keepdims=True))\n",
    "y_hat = e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "y_hat_clipped = np.clip(y_hat, np.finfo(float).eps, 1 - np.finfo(float).eps)\n",
    "\n",
    "# Cross entropy\n",
    "neg_logs = np.sum(y * -np.log(y_hat_clipped), axis=1)\n",
    "\n",
    "new_cce_loss = np.mean(neg_logs)\n",
    "\n",
    "print(f'New loss: {new_cce_loss}')\n",
    "print(f'Previous loss: {cce_loss}')\n",
    "\n",
    "# Hence the new loss decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But this way is very lenthy confusing and not applicable for large scale\n",
    "# therefore we will be using frameworks for faster implementation int any big projects. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
